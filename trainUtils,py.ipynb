{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74cff847",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mModel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CardModel\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_model\u001b[39m(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSHAIKH SOHEL\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mimages-20221209T180836Z-001\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodified_mobilenet_v2_features_state_dict.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, load_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, cuda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, decay_points\u001b[38;5;241m=\u001b[39m[], decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m):    \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Model'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from Model import CardModel\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def init_model(path=r\"C:\\Users\\SHAIKH SOHEL\\Downloads\\images-20221209T180836Z-001\\modified_mobilenet_v2_features_state_dict.pth\", load_model=False, cuda=False, lr=1e-3, decay_points=[], decay=0.1):    \n",
    "    print('initizalizing Model...')\n",
    "    model = CardModel(path=path, load=(not load_model))\n",
    "    if load_model:\n",
    "        model.load_state_dict(torch.load(path), strict=True)\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "        \n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, betas=(0.9,0.999))\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_points, gamma=decay)\n",
    "    print('Model loaded...')\n",
    "    return model, optimizer, scheduler\n",
    "\n",
    "\n",
    "def calculate_predictions(out):\n",
    "    predicted = np.argmax(out, axis=1)\n",
    "    return predicted\n",
    "\n",
    "def train(model, optimizer, loader, epoch_i, cuda=False):\n",
    "    model.train()\n",
    "    loss = 0.0\n",
    "    avg = 0.0\n",
    "    start = time.time()\n",
    "    loss_hist = []\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for batch_idx, data in enumerate(loader, 1):\n",
    "        batch_time_s = time.time()\n",
    "\n",
    "        y = torch.squeeze(data['label'])\n",
    "        x = data['image']\n",
    "        if cuda:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = model.criter(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        out = out.cpu().detach().numpy()\n",
    "        preds = calculate_predictions(out)\n",
    "        predictions += list(preds)\n",
    "        y = y.cpu().detach().numpy()\n",
    "        labels += list(y)\n",
    "        # metrics\n",
    "        accuracy = metrics.accuracy_score(y, preds)\n",
    "        precision = metrics.precision_score(y, preds, average='weighted',zero_division=1)\n",
    "        recall = metrics.recall_score(y, preds, average='weighted',zero_division=1)\n",
    "        f1_score = metrics.f1_score(y, preds, average='weighted',zero_division=1)\n",
    "        \n",
    "        loss = float(loss.detach())\n",
    "        loss_hist.append(loss)\n",
    "        avg += loss\n",
    "        \n",
    "        spent_time = time.time() - batch_time_s\n",
    "        out_str = '\\rTRAIN Epoch: {} Loss: {:.6f} Acc: {:5.2f} preci: {:.3f} recall: {:.3f} f1 score: {:.3f} time: {:.2f}{}'.format(\n",
    "                epoch_i, loss, 100*accuracy, precision, recall, f1_score, spent_time, 10*' ')\n",
    "        print('\\r'+out_str, end='')\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "    predictions = np.array(predictions)\n",
    "    accuracy = metrics.accuracy_score(labels, predictions)\n",
    "    precision = metrics.precision_score(labels, predictions, average='weighted',zero_division=1)\n",
    "    recall = metrics.recall_score(labels, predictions, average='weighted',zero_division=1)\n",
    "    f1_score = metrics.f1_score(labels, predictions, average='weighted',zero_division=1)\n",
    "    \n",
    "    total_time = time.time() - start\n",
    "    avg /= len(loader)\n",
    "    out_str = 'TRAIN Epoch: {} Avg Loss: {:.6f} Acc: {:5.2f} preci: {:.3f} recall: {:.3f} f1 score: {:.3f} time: {:.2f}{}'.format(\n",
    "            epoch_i, avg, 100*accuracy, precision, recall, f1_score, total_time, 10*' ')\n",
    "    print('\\r'+out_str)\n",
    "    \n",
    "    return loss_hist, avg, accuracy, precision, recall, f1_score\n",
    "\n",
    "\n",
    "def validation(model, loader, epoch_i, cuda=False, type_t='VAL'):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss = 0.0\n",
    "        avg = 0.0\n",
    "        start = time.time()\n",
    "        loss_hist = []\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        for batch_idx, data in enumerate(loader, 1):\n",
    "            batch_time_s = time.time()\n",
    "\n",
    "            y = torch.squeeze(data['label'])\n",
    "            x = data['image']\n",
    "            if cuda:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            \n",
    "            out = model(x)\n",
    "            loss = float(model.criter(out, y).detach_())\n",
    "            loss_hist.append(loss)\n",
    "            avg += loss\n",
    "            \n",
    "            out = out.cpu().detach().numpy()\n",
    "            preds = calculate_predictions(out)\n",
    "            predictions += list(preds)\n",
    "            y = y.cpu().detach().numpy()\n",
    "            labels += list(y)\n",
    "            # metrics\n",
    "            accuracy = metrics.accuracy_score(y, preds)\n",
    "            precision = metrics.precision_score(y, preds, average='weighted',zero_division=1)\n",
    "            recall = metrics.recall_score(y, preds, average='weighted',zero_division=1)\n",
    "            f1_score = metrics.f1_score(y, preds, average='weighted',zero_division=1)\n",
    "        \n",
    "            spent_time = time.time() - batch_time_s\n",
    "            \n",
    "            out_str = '\\r{} Epoch: {} Loss: {:.6f} Acc: {:5.2f} preci: {:.3f} recall: {:.3f} f1 score: {:.3f} time: {:.2f}{}'.format(\n",
    "                    type_t, epoch_i, loss, 100*accuracy, precision, recall, f1_score, spent_time, 10*' ')\n",
    "            print('\\r'+out_str, end='')\n",
    "        \n",
    "        labels = np.array(labels)\n",
    "        predictions = np.array(predictions)\n",
    "        accuracy = metrics.accuracy_score(labels, predictions)\n",
    "        precision = metrics.precision_score(labels, predictions, average='weighted',zero_division=1)\n",
    "        recall = metrics.recall_score(labels, predictions, average='weighted',zero_division=1)\n",
    "        f1_score = metrics.f1_score(labels, predictions, average='weighted',zero_division=1)\n",
    "        \n",
    "        total_time = time.time() - start\n",
    "        avg /= len(loader)\n",
    "        out_str = '{} Epoch: {} Avg Loss: {:.6f} Acc: {:5.2f} preci: {:.3f} recall: {:.3f} f1 score: {:.3f} time: {:.2f}{}'.format(\n",
    "                type_t, epoch_i, avg, 100*accuracy, precision, recall, f1_score, total_time, 10*' ')\n",
    "        print('\\r'+out_str)\n",
    "        \n",
    "        return loss_hist, avg, accuracy, precision, recall, f1_score\n",
    "    \n",
    "    \n",
    "def predict_from_loader(model, loader, cuda=False):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss = 0.0\n",
    "        avg = 0.0\n",
    "        start = time.time()\n",
    "        loss_hist = []\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        for batch_idx, data in enumerate(loader, 1):\n",
    "            batch_time_s = time.time()\n",
    "\n",
    "            y = torch.squeeze(data['label'])\n",
    "            x = data['image']\n",
    "            if cuda:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            \n",
    "            out = model(x)\n",
    "            loss = float(model.criter(out, y).detach_())\n",
    "            loss_hist.append(loss)\n",
    "            avg += loss\n",
    "            \n",
    "            out = out.cpu().detach().numpy()\n",
    "            preds = calculate_predictions(out)\n",
    "            predictions += list(preds)\n",
    "            y = y.cpu().detach().numpy()\n",
    "            labels += list(y)\n",
    "            # metrics\n",
    "            accuracy = metrics.accuracy_score(y, preds)\n",
    "            precision = metrics.precision_score(y, preds, average='weighted',zero_division=1)\n",
    "            recall = metrics.recall_score(y, preds, average='weighted',zero_division=1)\n",
    "            f1_score = metrics.f1_score(y, preds, average='weighted',zero_division=1)\n",
    "        \n",
    "            spent_time = time.time() - batch_time_s\n",
    "            \n",
    "            out_str = '\\r{:5.2f}% {}/{} Loss: {:.6f} Acc: {:5.2f} preci: {:.3f} recall: {:.3f} f1 score: {:.3f} time: {:.2f}{}'.format(\n",
    "                    100*batch_idx/len(loader), batch_idx, len(loader), loss, 100*accuracy, precision, recall, f1_score, spent_time, 10*' ')\n",
    "            print('\\r'+out_str, end='')\n",
    "            \n",
    "        labels = np.array(labels)\n",
    "        predictions = np.array(predictions)\n",
    "        accuracy = metrics.accuracy_score(labels, predictions)\n",
    "        precision = metrics.precision_score(labels, predictions, average='weighted',zero_division=1)\n",
    "        recall = metrics.recall_score(labels, predictions, average='weighted',zero_division=1)\n",
    "        f1_score = metrics.f1_score(labels, predictions, average='weighted',zero_division=1)\n",
    "        \n",
    "        total_time = time.time() - start\n",
    "        avg /= len(loader)\n",
    "        out_str = 'Avg Loss: {:.6f} Acc: {:5.2f} preci: {:.3f} recall: {:.3f} f1 score: {:.3f} time: {:.2f}{}'.format(\n",
    "                avg, 100*accuracy, precision, recall, f1_score, total_time, 10*' ')\n",
    "        print('\\r'+out_str)\n",
    "        \n",
    "        return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc826df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
